{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4fd9188a",
   "metadata": {},
   "source": [
    "# 04_previsao_ultrafast_parquet (⚡ Ultra Rápido)\n",
    "Janela reduzida (N meses), 1 fold, calendário + lag1, Ridge & LightGBM, salva pipeline vencedor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "184ca92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1) IMPORTS & CONFIG\n",
    "import os, json, warnings\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.preprocessing import OrdinalEncoder, StandardScaler, FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Ridge\n",
    "try:\n",
    "    from lightgbm import LGBMRegressor\n",
    "except Exception:\n",
    "    import sys, subprocess\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", \"-q\", \"lightgbm\"], check=False)\n",
    "    from lightgbm import LGBMRegressor\n",
    "import joblib\n",
    "\n",
    "OUT_DIR = Path(\"./outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "DEFAULT_PARQUET = os.environ.get(\"INPUT_FILE\", r\"/mnt/data/base_mensal_with_clusters (2).parquet\")\n",
    "DATE_COL, TARGET_COL, GRAIN_KEYS = \"year_month\", \"sales\", [\"store\",\"item\"]\n",
    "SEED, N_THREADS, MAX_MONTHS = 42, 2, int(os.environ.get(\"MAX_MONTHS\", 18))\n",
    "USE_LAG1 = True\n",
    "np.random.seed(SEED)\n",
    "print(f\"[INFO] Parquet: {DEFAULT_PARQUET} | MAX_MONTHS={MAX_MONTHS} | USE_LAG1={USE_LAG1}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031a1f87",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2) UTILS\n",
    "def read_parquet_efficient(path, date_col):\n",
    "    df = pd.read_parquet(path, engine=\"pyarrow\")\n",
    "    for c in df.select_dtypes(include=[\"int\", \"Int64\"]).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"integer\")\n",
    "    for c in df.select_dtypes(include=[\"float\"]).columns:\n",
    "        df[c] = pd.to_numeric(df[c], downcast=\"float\")\n",
    "    if date_col in df.columns:\n",
    "        df[date_col] = pd.to_datetime(df[date_col], errors=\"coerce\")\n",
    "        df[date_col] = df[date_col].values.astype(\"datetime64[M]\")\n",
    "    for c in df.select_dtypes(include=[\"object\", \"string\"]).columns:\n",
    "        if df[c].nunique(dropna=True) < 5000 and df[c].nunique(dropna=True) / max(1,len(df)) < 0.5:\n",
    "            df[c] = df[c].astype(\"category\")\n",
    "    if \"cluster\" in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[\"cluster\"]):\n",
    "            df[\"cluster\"] = pd.to_numeric(df[\"cluster\"], downcast=\"integer\")\n",
    "        df[\"cluster\"] = df[\"cluster\"].astype(\"category\")\n",
    "    return df\n",
    "\n",
    "def add_calendar_features_inplace(df, date_col):\n",
    "    df[\"year\"]  = df[date_col].dt.year.astype(\"int16\")\n",
    "    df[\"month\"] = df[date_col].dt.month.astype(\"int8\")\n",
    "    df[\"quarter\"] = df[date_col].dt.quarter.astype(\"int8\")\n",
    "    df[\"month_sin\"] = np.sin(2*np.pi*df[\"month\"]/12).astype(\"float32\")\n",
    "    df[\"month_cos\"] = np.cos(2*np.pi*df[\"month\"]/12).astype(\"float32\")\n",
    "\n",
    "def add_group_lag1_inplace(df, keys, date_col, target):\n",
    "    df.sort_values([*keys, date_col], inplace=True, kind=\"stable\")\n",
    "    df[\"lag1\"] = df.groupby(keys, observed=True)[target].shift(1).astype(\"float32\")\n",
    "    med = df.groupby(keys, observed=True)[target].transform(\"median\")\n",
    "    df[\"lag1\"] = df[\"lag1\"].fillna(med).fillna(df[target].median()).astype(\"float32\")\n",
    "\n",
    "def limit_to_last_n_months(df, date_col, n_months):\n",
    "    months = sorted(df[date_col].dt.to_period(\"M\").unique())\n",
    "    if len(months) > n_months:\n",
    "        keep = set(months[-n_months:])\n",
    "        return df[df[date_col].dt.to_period(\"M\").isin(keep)].reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    return float(np.sqrt(mean_squared_error(y_true, y_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80a6b3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3) LOAD + SHRINK + FEATURES\n",
    "src = DEFAULT_PARQUET\n",
    "assert Path(src).exists(), f\"Parquet não encontrado: {src}\"\n",
    "df = read_parquet_efficient(src, DATE_COL)\n",
    "if df[TARGET_COL].isna().any():\n",
    "    df = df.loc[~df[TARGET_COL].isna()].reset_index(drop=True)\n",
    "df = limit_to_last_n_months(df, DATE_COL, MAX_MONTHS)\n",
    "for k in GRAIN_KEYS: assert k in df.columns, f\"Ausente: {k}\"\n",
    "add_calendar_features_inplace(df, DATE_COL)\n",
    "if USE_LAG1: add_group_lag1_inplace(df, GRAIN_KEYS, DATE_COL, TARGET_COL)\n",
    "features = [c for c in df.columns if c not in {DATE_COL, TARGET_COL}]\n",
    "print(\"[INFO] Features:\", len(features))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6259892f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4) 1-FOLD TEMPORAL SPLIT (último mês)\n",
    "all_months = sorted(df[DATE_COL].dt.to_period(\"M\").unique())\n",
    "val_month = all_months[-1]\n",
    "train_mask = df[DATE_COL].dt.to_period(\"M\") < val_month\n",
    "val_mask   = df[DATE_COL].dt.to_period(\"M\") == val_month\n",
    "X_train, y_train = df.loc[train_mask, features], df.loc[train_mask, TARGET_COL].astype(\"float32\")\n",
    "X_val,   y_val   = df.loc[val_mask, features],   df.loc[val_mask, TARGET_COL].astype(\"float32\")\n",
    "print(f\"[SPLIT] Train={X_train.shape} | Val={X_val.shape} | ValMonth={val_month}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd3b8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5) MODELOS (Ridge + LightGBM)\n",
    "cat_cols = list(df[features].select_dtypes(include=[\"category\",\"object\",\"string\"]).columns)\n",
    "num_cols = [c for c in features if c not in cat_cols]\n",
    "\n",
    "ridge_pre = ColumnTransformer([\n",
    "    (\"num\", StandardScaler(with_mean=False), num_cols),\n",
    "    (\"cat\", OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1), cat_cols)\n",
    "], remainder=\"drop\", sparse_threshold=0.3)\n",
    "\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "def ensure_categories(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    X = X.copy()\n",
    "    for c in cat_cols:\n",
    "        if c in X.columns:\n",
    "            X[c] = X[c].astype(\"category\")\n",
    "    return X\n",
    "ensure_cat_transformer = FunctionTransformer(ensure_categories, validate=False)\n",
    "\n",
    "ridge = Pipeline([(\"pre\", ridge_pre), (\"est\", Ridge(alpha=1.0, random_state=SEED))])\n",
    "\n",
    "lgbm = Pipeline([\n",
    "    (\"pre\", ensure_cat_transformer),\n",
    "    (\"est\", LGBMRegressor(\n",
    "        objective=\"regression\",\n",
    "        learning_rate=0.12, n_estimators=600,\n",
    "        num_leaves=31, min_child_samples=120,\n",
    "        subsample=0.8, colsample_bytree=0.8,\n",
    "        reg_lambda=1.0, reg_alpha=0.0,\n",
    "        max_bin=191, n_jobs=2, random_state=SEED\n",
    "    ))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29654d80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 6) TREINO & AVALIAÇÃO\n",
    "ridge.fit(X_train, y_train)\n",
    "pred_ridge = ridge.predict(X_val)\n",
    "rmse_ridge = rmse(y_val, pred_ridge)\n",
    "print(f\"[Ridge] RMSE val: {rmse_ridge:.4f}\")\n",
    "\n",
    "lgbm.fit(X_train, y_train, est__eval_set=[(X_val, y_val)], est__early_stopping_rounds=40, est__verbose=False)\n",
    "best_iter = getattr(lgbm.named_steps[\"est\"], \"best_iteration_\", None) or 300\n",
    "pred_lgbm = lgbm.predict(X_val)\n",
    "rmse_lgbm = rmse(y_val, pred_lgbm)\n",
    "print(f\"[LightGBM] RMSE val: {rmse_lgbm:.4f} | best_iter≈{best_iter}\")\n",
    "\n",
    "import pandas as pd\n",
    "metrics_df = pd.DataFrame([\n",
    "    {\"model\":\"Ridge\",\"rmse_val\":rmse_ridge},\n",
    "    {\"model\":\"LightGBM\",\"rmse_val\":rmse_lgbm}\n",
    "]).sort_values(\"rmse_val\", ascending=True).reset_index(drop=True)\n",
    "metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "718741ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 7) VENCEDOR & SALVAR PIPELINE\n",
    "winner = metrics_df.iloc[0][\"model\"]\n",
    "print(f\"[WINNER] {winner}\")\n",
    "if winner == \"Ridge\":\n",
    "    final = ridge\n",
    "else:\n",
    "    final_rounds = int(min(max(150, best_iter), 400))\n",
    "    final = Pipeline([\n",
    "        (\"pre\", lgbm.named_steps[\"pre\"]),\n",
    "        (\"est\", lgbm.named_steps[\"est\"].set_params(n_estimators=final_rounds))\n",
    "    ])\n",
    "final.fit(df[features], df[TARGET_COL].astype(\"float32\"))\n",
    "\n",
    "schema = {\n",
    "    \"date_col\": DATE_COL, \"target_col\": TARGET_COL, \"grain_keys\": GRAIN_KEYS,\n",
    "    \"features\": features, \"categoricals\": cat_cols, \"winner_model\": str(winner)\n",
    "}\n",
    "fallback = {\n",
    "    \"numeric_median\": {c: float(df[c].median()) for c in df[features].select_dtypes(include=[\"number\"]).columns},\n",
    "    \"categorical_default\": \"missing\"\n",
    "}\n",
    "OUT_DIR = Path(\"./outputs\"); OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "joblib.dump(final, OUT_DIR / \"best_model_pipeline.pkl\")\n",
    "with open(OUT_DIR / \"schema.json\",\"w\",encoding=\"utf-8\") as f: json.dump(schema, f, ensure_ascii=False, indent=2)\n",
    "with open(OUT_DIR / \"fallback_stats.json\",\"w\",encoding=\"utf-8\") as f: json.dump(fallback, f, ensure_ascii=False, indent=2)\n",
    "print(\"[FILES] Salvos em ./outputs/\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
